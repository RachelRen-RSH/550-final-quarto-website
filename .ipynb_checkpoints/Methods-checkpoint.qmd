---
title: "Methods"
---


Our application is constructed with Python and Jupyter notebook. The website is designed in Quarto, and it is published through Github pages. The whole process of developing the application is divided in three steps below.


## Data Collection
### 1. Web Scraping
To retrieve the hotel prices during the Christmas holiday season in Miami, we web-scraped Expedia.com, an official website of booking stays and flights, by selecting a one-night stay from December 24th to December 25th in 2023 with one traveler and one room. We used Selenium and BeautifulSoup to extract the information of hotel names, ratings, amenities, and prices from the HTML tags and classes and generated a dataframe with the cleaned data.

![Expedia Query Result Screenshot](images/Expedia.png)

### 2. Google Geocoding API
Since the web-scraped results do not include specific addresses or coordinates of hotels, we used Google Geocoding API to geocode the addresses from the hotel names. Then we withdrawed the coordinates from the geocoding results and joined them by hotel names into the hotel's dataframe to create a geodataframe with geometries. 

### 3. Census API
It is possible that a hotel's price is related with the wealth level of the belonged neighborhood. Therefore, we retrieved the median household income data by census tracts and joined it with the hotel dataframe.

### 4. ArcGIS Open Data 
Spatial features of parks, shorelines, matro stations, trash complaints, abandoned cars and properties and sexual offenders are all retrieved from County of Miami-Dade ArcGIS Open Data Portal. We performed a nearest-neighborhood analysis to calculate the distance from each hotel to its nearest neighbor in the these datasets. We did a logarithm of the distances to normalize the distribution of distance values.

## Data Visualization

## Regression Analysis




